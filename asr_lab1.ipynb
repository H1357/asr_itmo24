{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e5b3f1c-f656-4b44-9385-7bfcd1558469",
   "metadata": {},
   "source": [
    "# Лабораторная работа 1. Подсчет ошибки распознавания"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5c72b7-e242-412c-851c-02479bff8773",
   "metadata": {},
   "source": [
    "WER (Word Error Rate) является метрикой для оценки качества систем распознавания речи. Она показывает процент ошибочных слов в гипотезе распознавания по сравнению с эталонным текстом. WER учитывает три типа ошибок: вставки, удаления и замены. \n",
    "$$ WER = {I + D + S \\over D + S + C} $$\n",
    "где I, D, S - количество втавок, удалений и замен, соответственно. C - количество правильно распознанных слов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa45f820-960d-47bd-bd7d-9bd284a239d7",
   "metadata": {},
   "source": [
    "Лабораторная работа состоит из трех частей. Первая часть (функция подсчета WER) обязательная, остальные дополнительные. Всего за работу можно получить максимум 20 баллов. 4 за сдачу в срок и 16 за задания: \n",
    "* функция подсчета WER (тест 1.a, 1.b) - 8 баллов\n",
    "* функция подсчета WER и ошибки пунктуации (тест 2.a) - 4 балла\n",
    "* функция подсчета SA-WER (тест 3.а) - 4 балла"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7765f57-93d1-4310-b2c6-b88189c16099",
   "metadata": {},
   "source": [
    "# 1. Word Error Rate (8 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af47bb7-3c52-4d0f-aa72-426bad9089fc",
   "metadata": {},
   "source": [
    "## 1.a. подсчет WER \n",
    "\n",
    "\n",
    "Функция должна принимать две строки в качестве входных данных: эталонный текст и распознанный текст. Эталонный текст - это то, что произносится в аудиозаписи, а гипотеза распознавания - это текст, полученный от системы распознавания речи. Для корректного вычисления ошибки распознавания необходимо удалить все символы пунктуации и привести все слова к нижнему регистру.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "06e89202-5b26-4a55-b3a0-2e1996d07552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Error Rate: 33.33%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def calculate_wer(reference_text: str, recognized_text: str) -> float:\n",
    "    # Приведение текста к нижнему регистру, удаление символов пунктуации и разбивка на слова\n",
    "    \n",
    "    import string\n",
    "    reference_words = reference_text.lower().translate(str.maketrans('', '', string.punctuation)).split()\n",
    "    recognized_words = recognized_text.lower().translate(str.maketrans('', '', string.punctuation)).split()\n",
    "\n",
    "    # расстояние Левенштейна \n",
    "    \n",
    "    # Инициализация матрицы для подсчета расстояния между словами\n",
    "    distance_matrix = [[0] * (len(recognized_words) + 1) for _ in range(len(reference_words) + 1)]\n",
    "\n",
    "    \n",
    "    # Наполнение первой строки матрицы\n",
    "    for i in range(len(reference_words) + 1):\n",
    "        distance_matrix[i][0] = i\n",
    "\n",
    "    # Наполнение первого столбца матрицы\n",
    "    for j in range(len(recognized_words) + 1):\n",
    "        distance_matrix[0][j] = j\n",
    "\n",
    "    \n",
    "\n",
    "    # Заполнение матрицы расстояний методом динамического программирования\n",
    "    # нашел тут инструкцию https://habr.com/ru/articles/676858/\n",
    "\n",
    "    for i in range(1, len(reference_words) + 1):\n",
    "        for j in range(1, len(recognized_words) + 1):\n",
    "            cost = 0 if reference_words[i - 1] == recognized_words[j - 1] else 1 # если слова одинаковы то штраф == 0\n",
    "            \n",
    "            distance_matrix[i][j] = min(\n",
    "                distance_matrix[i - 1][j] + 1,  # смотрим выше на одну строку\n",
    "                distance_matrix[i][j - 1] + 1,  # смотрим на предыдущий столбец\n",
    "                distance_matrix[i - 1][j - 1] + cost  # смотрим на предыдущйю ячейку по диагонали (алг Вагнера — Фишера может приснится только в кошмаре)\n",
    "            )\n",
    "            \n",
    "            #from tabulate import tabulate\n",
    "            #print(tabulate(distance_matrix, headers=reference_words, showindex=['',*recognized_words] ))\n",
    "    # Расчет WER (в процентах)\n",
    "    \n",
    "    wer = distance_matrix[len(reference_words)][len(recognized_words)] / len(reference_words) * 100 if reference_words else 0\n",
    "    return wer\n",
    "\n",
    "wer = calculate_wer('Я ел солонину', 'Я ел слона')\n",
    "print(f\"Word Error Rate: {wer:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f604bfbe-3af2-4550-9119-9031b65a06d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1.a passed\n"
     ]
    }
   ],
   "source": [
    "def assert_wer(ref, hyp, ideal_wer):\n",
    "    wer = calculate_wer(ref, hyp)\n",
    "    assert round(wer, 2) == round(ideal_wer, 2), f\"for '{hyp=}' and '{ref=}' {ideal_wer=}, calculate_wer {wer=}\"\n",
    "    \n",
    "def test_wer():\n",
    "    assert_wer('привет студент', 'привет студент', 0)\n",
    "    assert_wer('привет! Студент.', 'Привет, студент?', 0)\n",
    "    assert_wer('привет студент', 'студент', 50)\n",
    "    assert_wer('привет студент', '', 100)\n",
    "    assert_wer('привет студент', 'студент привет', 100)\n",
    "    assert_wer('привет', 'привет студент', 100)\n",
    "    assert_wer('привет студент привет как дела', 'студент привет', 60)\n",
    "    assert_wer('привет студент привет как дела', 'привет как дела', 40)\n",
    "    assert_wer('привет студент привет как дела ', 'привет студент дела ', 40)\n",
    "    assert_wer('привет студент привет как дела '*100, 'привет студент дела '*100, 40)\n",
    "\n",
    "    print(f\"Test 1.a passed\")\n",
    "    \n",
    "test_wer() \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b32777-0fae-4999-9843-88313c1e3607",
   "metadata": {},
   "source": [
    "## 1.b. Построение выравнивания\n",
    "Реализованная в части 1.a. функция выдает только суммарное значение ошибки распознавания, не давая понимания, в чем состоят основные проблемы распознавания. \n",
    "\n",
    "Значение WER получается из трех видов ошибок: \n",
    "* вставка (insertion)\n",
    "* удаление (deletion)\n",
    "* замена (substitution)\n",
    "\n",
    "Каждый тип ошибок имеет свое значение и указывает на определенные недостатки системы. Например, большое количество вставок означает, что ASR слышит речь там где ее нет. А большое количество удалений показывает, что целевая речь пропускается и не транскрибируется. \n",
    "\n",
    "Кроме числовых значений каждой ошибки, для анализа результатов работы системы может пригодиться выравнивание эталонной текстовки и гипотезы распознавания относительно друг друга. \n",
    "\n",
    "пример выравнивания: \n",
    "\n",
    "```\n",
    ">>> tabulate(ali)\n",
    "\n",
    "Я сегодня  ***   учуcь  в  универе\n",
    "Я    с    завтра учусь *** универе  \n",
    "C    S      I      C    D    C    \n",
    "```\n",
    "\n",
    "Реализуйте функцию, которая кроме числового значения WER возвращает выравнивание, а также значения каждого типа ошибок распознавания (вставки, удаления, замены)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "414a0cdb-7230-493a-93ba-2d15547a537a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tabulate in c:\\users\\podoinitsyn\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.9.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tabulate\n",
    "from tabulate import tabulate\n",
    "# используйте tabulate для отладки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d6d7687-ff3a-4a46-80ec-12efcab49027",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_wer_with_alignment(reference_text: str, recognized_text: str):\n",
    "    \n",
    "    \n",
    "    import string\n",
    "    reference_words = reference_text.lower().translate(str.maketrans('', '', string.punctuation)).split()\n",
    "    recognized_words = recognized_text.lower().translate(str.maketrans('', '', string.punctuation)).split()\n",
    "\n",
    "    # расстояние Левенштейна \n",
    "    \n",
    "    # Инициализация матрицы для подсчета расстояния между словами\n",
    "    distance_matrix = [[0] * (len(recognized_words) + 1) for _ in range(len(reference_words) + 1)]\n",
    "\n",
    "    \n",
    "    # Наполнение первой строки матрицы\n",
    "    for i in range(len(reference_words) + 1):\n",
    "        distance_matrix[i][0] = i\n",
    "\n",
    "    # Наполнение первого столбца матрицы\n",
    "    for j in range(len(recognized_words) + 1):\n",
    "        distance_matrix[0][j] = j\n",
    "\n",
    "    \n",
    "\n",
    "    # Заполнение матрицы расстояний методом динамического программирования\n",
    "    for i in range(1, len(reference_words) + 1):\n",
    "        for j in range(1, len(recognized_words) + 1):\n",
    "            cost = 0 if reference_words[i - 1] == recognized_words[j - 1] else 1 # если слова одинаковы то штраф == 0\n",
    "            \n",
    "            distance_matrix[i][j] = min(\n",
    "                distance_matrix[i - 1][j] + 1,  # смотрим выше на одну строку (удаление)\n",
    "                distance_matrix[i][j - 1] + 1,  # смотрим на предыдущий столбец (вставка)\n",
    "                distance_matrix[i - 1][j - 1] + cost  # смотрим на предыдущйю ячейку по диагонали (замена)\n",
    "            )\n",
    "            \n",
    "            #print(distance_matrix)\n",
    "    # Расчет WER (в процентах)\n",
    "    \n",
    "    wer = distance_matrix[len(reference_words)][len(recognized_words)] / len(reference_words) * 100 if reference_words else 0\n",
    "\n",
    "    # используя distance_matrix восстановите путь (набор операций), который соответстует найденому WER \n",
    "    #TODO\n",
    "\n",
    "    # Восстановление пути по матрице расстояний\n",
    "    # нашел тут иструкцию https://habr.com/ru/articles/117063/\n",
    "\n",
    "    i, j = len(reference_words), len(recognized_words)\n",
    "    ali_ref, ali_hyp, ali_ops = [], [], []  # алигнмент для референса, гипотезы и операций\n",
    "    correct, deletion, insertion, substitution = 0, 0, 0, 0\n",
    "\n",
    "    while i > 0 or j > 0:\n",
    "        if i > 0 and j > 0 and distance_matrix[i][j] == distance_matrix[i - 1][j - 1] + (1 if reference_words[i - 1] != recognized_words[j - 1] else 0):\n",
    "            ali_ref.append(reference_words[i - 1])\n",
    "            ali_hyp.append(recognized_words[j - 1])\n",
    "            if reference_words[i - 1] == recognized_words[j - 1]:\n",
    "                ali_ops.append(\"C\")  # Correct\n",
    "                correct += 1\n",
    "            else:\n",
    "                ali_ops.append(\"S\")  # Substitution\n",
    "                substitution += 1\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "        elif i > 0 and distance_matrix[i][j] == distance_matrix[i - 1][j] + 1:\n",
    "            ali_ref.append(reference_words[i - 1])\n",
    "            ali_hyp.append(\"***\")  # Вставка в гипотезу\n",
    "            ali_ops.append(\"D\")  # Deletion\n",
    "            deletion += 1\n",
    "            i -= 1\n",
    "        else:\n",
    "            ali_ref.append(\"***\")\n",
    "            ali_hyp.append(recognized_words[j - 1])\n",
    "            ali_ops.append(\"I\")  # Insertion\n",
    "            insertion += 1\n",
    "            j -= 1\n",
    "\n",
    "    # Переворачиваем алигнмент, так как шли от конца к началу\n",
    "    ali_ref.reverse()\n",
    "    ali_hyp.reverse()\n",
    "    ali_ops.reverse()\n",
    "\n",
    "    ali = [ali_ref, ali_hyp, ali_ops]\n",
    "\n",
    "    # ali[0]=  разбитый по словам референс. Втавки отабражаются в эталонном выравнивании с помощью \"***\"\n",
    "    # ali[1] = разбитая по словам гипотеза.\n",
    "    # ali[2] = аннотация \n",
    "    assert len(ali[0]) == len(ali[1]) == len(ali[2]), f\"wrong ali {ali}\"\n",
    "    \n",
    "    return {\"wer\" : wer,\n",
    "            \"cor\": correct, \n",
    "            \"del\": deletion,\n",
    "            \"ins\": insertion,\n",
    "            \"sub\": substitution,\n",
    "            \"ali\": ali}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f0ed11e-8d37-4478-bef2-fe9d41755d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_wer_with_alignment(reference_text: str, recognized_text: str):\n",
    "    return {\n",
    "            \"wer\" : 0,\n",
    "            \"cor\": 2, \n",
    "            \"del\": 0,\n",
    "            \"ins\": 0,\n",
    "            \"sub\": 0,\n",
    "            \"ali\": [[\"привет\", \"студент\"],[\"привет\", \"студент\"],['C', 'C']]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ff4fe6c-c548-4f60-bcf9-95a164f43645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1.b passed\n"
     ]
    }
   ],
   "source": [
    "def assert_wer_with_alignment(ref, hyp, ideal_report):\n",
    "    report = calculate_wer_with_alignment(ref, hyp)\n",
    "    for k, v in ideal_report.items():\n",
    "        if isinstance(v, float):\n",
    "            assert round(v, 2) == round(report[k], 2), f\"for '{hyp=}' and '{ref=}' {ideal_report=}, calculate_wer {report=}\"\n",
    "        else:\n",
    "            assert v == report[k], f\"for '{hyp=}' and '{ref=}' {ideal_report=}, calculate_wer {report=}\"\n",
    "\n",
    "    \n",
    "def test_wer_with_alignment():\n",
    "    assert_wer_with_alignment('привет студент', 'привет студент',  {\n",
    "            \"wer\" : 0,\n",
    "            \"cor\": 2, \n",
    "            \"del\": 0,\n",
    "            \"ins\": 0,\n",
    "            \"sub\": 0,\n",
    "            \"ali\": [[\"привет\", \"студент\"],[\"привет\", \"студент\"],['C', 'C']]})\n",
    "    assert_wer_with_alignment('привет студент', 'студент', {\n",
    "            \"wer\" : 50,\n",
    "            \"cor\": 1, \n",
    "            \"del\": 1,\n",
    "            \"ins\": 0,\n",
    "            \"sub\": 0,\n",
    "            \"ali\": [[\"привет\", \"студент\"],[\"***\", \"студент\"],['D', 'C']]})\n",
    "    assert_wer_with_alignment('привет', 'привет студент', {\n",
    "            \"wer\" : 100,\n",
    "            \"cor\": 1, \n",
    "            \"del\": 0,\n",
    "            \"ins\": 1,\n",
    "            \"sub\": 0,\n",
    "            \"ali\": [[\"привет\", \"***\"],[\"привет\", \"студент\"],['C', 'I']]})\n",
    "    assert_wer_with_alignment('привет студент', 'пока студент',  {\n",
    "            \"wer\" : 50,\n",
    "            \"cor\": 1, \n",
    "            \"del\": 0,\n",
    "            \"ins\": 0,\n",
    "            \"sub\": 1,\n",
    "            \"ali\": [[\"привет\", \"студент\"],[\"пока\", \"студент\"],['S', 'C']]})\n",
    "\n",
    "    print(f\"Test 1.b passed\")\n",
    "    \n",
    "test_wer_with_alignment() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983a8e14-f4f1-4441-a72d-2fa693d72474",
   "metadata": {},
   "source": [
    "# 2. WER с пунктуацией (4 балла)\n",
    "Попробуйте модифицировать WER таким образом, чтобы получившаяся метрика учитавала ошибки расстановки знаков препинания. \n",
    "\n",
    "Для этого надо ввести ограничение в алгоритм подсчета distance_matrix таким образом, чтобы запретить делать замену знака препинания на слово и наоборот.\n",
    "\n",
    "Пример выравнивания \n",
    "```\n",
    "Я сегодня  .   ***   ***  А ты  \n",
    "Я    с    *** завтра  ?   А ты  \n",
    "C    S    D_p   I    I_p  C  C    \n",
    "```\n",
    "Здесь суффикс _p в аннотации к ошибкам означает **ошибки пунктуации**\n",
    "\n",
    "\n",
    "Задание: \n",
    "Напишите функцию, которая кроме стандартного WER считает дополнительно RichTranscriptErrorRate (RTER) по формуле\n",
    "\n",
    "$$ RTER = {I_p + D_p + S_p \\over D_p + S_p + C_p} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "726e8fa5-da39-4090-8272-c8fd053593f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_wer_per(reference_text: str, recognized_text: str):\n",
    "    \n",
    "    import string\n",
    "\n",
    "    # Списки знаков препинания\n",
    "    punctuation = set(string.punctuation)\n",
    "    \n",
    "    # Приведение к нижнему регистру и разделение на слова (включая знаки препинания)\n",
    "    import re\n",
    "    reference_words  = re.findall(r'\\w+|[^\\w\\s]', reference_text.lower(), re.UNICODE)\n",
    "    recognized_words = re.findall(r'\\w+|[^\\w\\s]', recognized_text.lower(), re.UNICODE)\n",
    "\n",
    "    print(reference_words)\n",
    "    # Инициализация матрицы для подсчета расстояния\n",
    "    distance_matrix = [[0] * (len(recognized_words) + 1) for _ in range(len(reference_words) + 1)]\n",
    "    \n",
    "    # Наполнение первой строки и первого столбца\n",
    "    for i in range(len(reference_words) + 1):\n",
    "        distance_matrix[i][0] = i\n",
    "    for j in range(len(recognized_words) + 1):\n",
    "        distance_matrix[0][j] = j\n",
    "    \n",
    "    # Переменные для подсчета ошибок\n",
    "    substitution_p, deletion_p, insertion_p, correct_p = 0, 0, 0, 0\n",
    "\n",
    "    dict_p = {'correct_p': 0,                   # попоробуем другой способ подсчета\n",
    "                       'deletion_p':0 ,\n",
    "                       'insertion_p':0,\n",
    "                       'substitution_p':0\n",
    "                       }\n",
    "\n",
    "\n",
    "    # Заполнение матрицы с учетом запрещения замены слова на знак препинания и наоборот\n",
    "    for i in range(1, len(reference_words) + 1):\n",
    "        for j in range(1, len(recognized_words) + 1):\n",
    "            ref_is_punct = reference_words[i - 1] in punctuation\n",
    "            rec_is_punct = recognized_words[j - 1] in punctuation\n",
    "\n",
    "            cost = 0          \n",
    "            if reference_words[i - 1] == recognized_words[j - 1]:\n",
    "                #cost = 0  # Совпадение\n",
    "                if ref_is_punct:   # два одинаковых знака препинания\n",
    "                    cost = 0  # Совпадение\n",
    "                    correct_p += 1  # Правильный знак препинания\n",
    "                    dict_p['correct_p']+= 1 # Правильный знак препинания\n",
    "\n",
    "                    #print('correct_p ', correct_p ,reference_words[i - 1],  recognized_words[j - 1] )\n",
    "\n",
    "            elif ref_is_punct != rec_is_punct: # токены не совпадают и один из них знак препинания\n",
    "                cost = 2  # Запрещаем замену слова на знак препинания или наоборот\n",
    "                if ref_is_punct:\n",
    "                    \n",
    "                    deletion_p += 1\n",
    "                    #print('deletion_p', deletion_p ,reference_words[i - 1],  recognized_words[j - 1] )\n",
    "                else:\n",
    "                    \n",
    "                    insertion_p += 1\n",
    "                    #print('insertion_p', insertion_p ,reference_words[i - 1],  recognized_words[j - 1] )\n",
    "            else:\n",
    "                #cost = 1  # Замена одного слова на другое\n",
    "                if ref_is_punct and rec_is_punct:\n",
    "                    cost = 1  # Замена одного слова на другое\n",
    "                    substitution_p += 1\n",
    "                    dict_p['substitution_p']+= 1\n",
    "                    #print('substitution_p', substitution_p ,reference_words[i - 1],  recognized_words[j - 1] )\n",
    "\n",
    "            list_for_matrix = [distance_matrix[i - 1][j] + 1,  # удаление\n",
    "                                distance_matrix[i][j - 1] + 1,  # вставка\n",
    "                                distance_matrix[i - 1][j - 1] + cost  # замена\n",
    "                                ]\n",
    "\n",
    "\n",
    "            distance_matrix[i][j] = min(list_for_matrix)\n",
    "            \n",
    "            '''\n",
    "            min_index = list_for_matrix.index(distance_matrix[i][j])\n",
    "            \n",
    "            if (ref_is_punct or rec_is_punct) and reference_words[i - 1] != recognized_words[j - 1]:  #если есть один или два знака препинания и они не совпадают\n",
    "                if min_index == 0:\n",
    "                    dict_p['deletion_p']+= 1\n",
    "                if min_index == 1:\n",
    "                    dict_p['insertion_p']+= 1\n",
    "\n",
    "            #print('для пары_',reference_words[i - 1], recognized_words[j - 1], 'действие № ', min_index  )\n",
    "                    \n",
    "    #substitution_p, deletion_p, insertion_p, correct_p = dict_p['substitution_p'], dict_p['deletion_p'], dict_p['insertion_p'], dict_p['correct_p']\n",
    "    #print( [substitution_p, deletion_p, insertion_p, correct_p] == [dict_p['substitution_p'], dict_p['deletion_p'], dict_p['insertion_p'], dict_p['correct_p']])\n",
    "        '''\n",
    "    # Расчет WER (в процентах)\n",
    "    wer = distance_matrix[len(reference_words)][len(recognized_words)] / len(reference_words) * 100 if reference_words else 0\n",
    "\n",
    "    # Вычисление PER по новой формуле\n",
    "    per = (insertion_p + deletion_p + substitution_p) / (deletion_p + substitution_p + correct_p) * 100 if (deletion_p + substitution_p + correct_p) > 0 else 0\n",
    "\n",
    "  \n",
    "\n",
    "    return {\"wer\" : calculate_wer(reference_text, recognized_text),\n",
    "            \"per\": per }\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "68a7febd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['привет', 'студент', '.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'wer': 50.0, 'per': 150.0}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_wer_per('привет студент.', 'студент.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "31f053d5-2015-4d33-8ded-e5d0160e8901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['привет', 'студент', '.']\n",
      "deletion_p 0 . привет\n",
      "deletion_p 0 . студент\n",
      "['привет', 'студент', '.']\n",
      "insertion_p 0 привет .\n",
      "insertion_p 0 студент .\n",
      "deletion_p 0 . студент\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "for 'hyp='студент.'' and 'ref='привет студент.'' ideal_report={'wer': 50, 'per': 0}, calculate_wer report={'wer': 50.0, 'per': 150.0}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[112], line 26\u001b[0m\n\u001b[0;32m     20\u001b[0m     assert_wer_per(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mпривет студент.\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.студент?\u001b[39m\u001b[38;5;124m'\u001b[39m, {\n\u001b[0;32m     21\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwer\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;241m50\u001b[39m,\n\u001b[0;32m     22\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mper\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m200\u001b[39m, })\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest 2 passed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 26\u001b[0m \u001b[43mtest_wer_per\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \n",
      "Cell \u001b[1;32mIn[112], line 14\u001b[0m, in \u001b[0;36mtest_wer_per\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest_wer_per\u001b[39m():\n\u001b[0;32m     11\u001b[0m     assert_wer_per(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mпривет студент.\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mпривет студент\u001b[39m\u001b[38;5;124m'\u001b[39m,  {\n\u001b[0;32m     12\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwer\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m     13\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mper\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m100\u001b[39m})\n\u001b[1;32m---> 14\u001b[0m     \u001b[43massert_wer_per\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mпривет студент.\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mстудент.\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mper\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m     assert_wer_per(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mпривет студент.\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mпривет. студент\u001b[39m\u001b[38;5;124m'\u001b[39m,  {\n\u001b[0;32m     18\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwer\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m     19\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mper\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m200\u001b[39m})\n\u001b[0;32m     20\u001b[0m     assert_wer_per(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mпривет студент.\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.студент?\u001b[39m\u001b[38;5;124m'\u001b[39m, {\n\u001b[0;32m     21\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwer\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;241m50\u001b[39m,\n\u001b[0;32m     22\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mper\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m200\u001b[39m, })\n",
      "Cell \u001b[1;32mIn[112], line 7\u001b[0m, in \u001b[0;36massert_wer_per\u001b[1;34m(ref, hyp, ideal_report)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mround\u001b[39m(v, \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mround\u001b[39m(report[k], \u001b[38;5;241m2\u001b[39m), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhyp\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mref\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mideal_report\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m, calculate_wer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreport\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m----> 7\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m v \u001b[38;5;241m==\u001b[39m report[k], \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhyp\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mref\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mideal_report\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m, calculate_wer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreport\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mAssertionError\u001b[0m: for 'hyp='студент.'' and 'ref='привет студент.'' ideal_report={'wer': 50, 'per': 0}, calculate_wer report={'wer': 50.0, 'per': 150.0}"
     ]
    }
   ],
   "source": [
    "def assert_wer_per(ref, hyp, ideal_report):\n",
    "    report = calculate_wer_per(ref, hyp)\n",
    "    for k, v in ideal_report.items():\n",
    "        if isinstance(v, float):\n",
    "            assert round(v, 2) == round(report[k], 2), f\"for '{hyp=}' and '{ref=}' {ideal_report=}, calculate_wer {report=}\"\n",
    "        else:\n",
    "            assert v == report[k], f\"for '{hyp=}' and '{ref=}' {ideal_report=}, calculate_wer {report=}\"\n",
    "\n",
    "    \n",
    "def test_wer_per():\n",
    "    assert_wer_per('привет студент.', 'привет студент',  {\n",
    "            \"wer\" : 0,\n",
    "            \"per\": 100})\n",
    "    assert_wer_per('привет студент.', 'студент.', {\n",
    "            \"wer\" : 50,\n",
    "            \"per\": 0,})\n",
    "    assert_wer_per('привет студент.', 'привет. студент',  {\n",
    "            \"wer\" : 0,\n",
    "            \"per\": 200})\n",
    "    assert_wer_per('привет студент.', '.студент?', {\n",
    "            \"wer\" : 50,\n",
    "            \"per\": 200, })\n",
    "\n",
    "    print(f\"Test 2 passed\")\n",
    "    \n",
    "test_wer_per() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb08f8da-e0f9-48e4-b584-3d1ab25c279c",
   "metadata": {},
   "source": [
    "# 3. Speaker-attributed Word Error Rate (4 балла)\n",
    "\n",
    "В задаче распознавания диалоговых данных, когда говорят два диктора, важно не только распознать правильно каждое слово, но и отнести его к правильному диктору. Чаще всего такой результат получается с помощью комбинации двух независимых систем: распознавания речи и диаризация. \n",
    "\n",
    "При подсчете ошибки распознавания диалоговых систем в формулу WER добавляется еще один тип ошибки - S_I (speaker incorrect).\n",
    "\n",
    "$$ SA{\\text -}WER = \\min{I + D + S + S_I \\over D + S + C + S_I} $$\n",
    "\n",
    "Кроме подсчета самой ошибки, sa-wer решает еще одну задачку - поиск маппинга из эталонных названий спикеров (например, имен) в предсказанные (чаще всего Idшники). Это необходимо, тк система диаризации не знает, какие названия у спикеров в эталоне. При подсчете SA-WER проверяются все возможные мапинги спикеров и выбирается тот, который соответствует минимальному значению ошибки. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "acb29784-c8cc-44bb-a8c4-118c5c0da9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def calculate_sawer(reference_text, reference_speakers, recognized_text, recognized_speakers):\n",
    "    # В отличие от прошлых функций на вход sawer подаются уже разбитые на слова произнесения\n",
    "    # Кроме списка слов, дополнительно передается список меток спикеров\n",
    "    assert isinstance(reference_text, list)\n",
    "    assert isinstance(recognized_text, list)\n",
    "    assert len(reference_text) == len(reference_speakers)\n",
    "    assert len(recognized_text) == len(recognized_speakers)\n",
    "    \n",
    "    #При подсчете ошибки распознавания диалоговых систем в формулу WER добавляется еще один тип ошибки - S_I (speaker incorrect) $$ SA{\\text -}WER = \\min{I + D + S + S_I \\over D + S + C + S_I} $$\n",
    "    # TODO  посчитайте sa-wer с учетом мапинга спикеров\n",
    "    # для этого посчитайте значение ошибки для каждого варианта мапинга меток дикторов \n",
    "    # и выберете тот, который соответствует минимальному SA-WER\n",
    "# Инициализируем переменные для хранения минимального SA-WER и соответствующего выравнивания\n",
    "    min_sawer = float('inf')\n",
    "    best_ali = []\n",
    "    \n",
    "    # Все возможные варианты маппинга спикеров\n",
    "    possible_mappings = list(itertools.permutations(set(recognized_speakers)))\n",
    "\n",
    "    for mapping in possible_mappings:\n",
    "        # Преобразуем метки распознанных спикеров в соответствии с текущей перестановкой\n",
    "        mapped_speakers = [mapping[recognized_speakers.index(speaker)] for speaker in recognized_speakers]\n",
    "\n",
    "        # Считаем обычные ошибки WER (I, D, S)\n",
    "        distance_matrix = [[0] * (len(recognized_text) + 1) for _ in range(len(reference_text) + 1)]\n",
    "        for i in range(1, len(reference_text) + 1):\n",
    "            for j in range(1, len(recognized_text) + 1):\n",
    "                cost = 0 if reference_text[i - 1] == recognized_text[j - 1] else 1\n",
    "                distance_matrix[i][j] = min(\n",
    "                    distance_matrix[i - 1][j] + 1,  # Удаление\n",
    "                    distance_matrix[i][j - 1] + 1,  # Вставка\n",
    "                    distance_matrix[i - 1][j - 1] + cost  # Замена\n",
    "                )\n",
    "        \n",
    "        # Считаем speaker incorrect (S_I)\n",
    "        speaker_errors = sum(1 for ref_sp, rec_sp in zip(reference_speakers, mapped_speakers) if ref_sp != rec_sp)\n",
    "\n",
    "        # Общие ошибки для вычисления SA-WER\n",
    "        I = len(recognized_text) - len(reference_text)  # Вставки\n",
    "        D = len(reference_text) - len(recognized_text)  # Удаления\n",
    "        S = distance_matrix[len(reference_text)][len(recognized_text)]  # Замены\n",
    "        SI = speaker_errors  # Ошибки спикеров\n",
    "\n",
    "        # Считаем SA-WER\n",
    "        C = len(reference_text) - S - D  # Верные совпадения\n",
    "        sawer = (I + D + S + SI) / (D + S + C + SI) * 100\n",
    "        \n",
    "        # Сохраняем минимальный SA-WER и соответствующее выравнивание\n",
    "        if sawer < min_sawer:\n",
    "            min_sawer = sawer\n",
    "            best_ali = {\n",
    "                \"reference\": reference_text,\n",
    "                \"recognized\": recognized_text,\n",
    "                \"reference_speakers\": reference_speakers,\n",
    "                \"mapped_speakers\": mapped_speakers\n",
    "            }\n",
    "    \n",
    "    return {\"sawer\": min_sawer, \"ali\": best_ali}\n",
    "\n",
    "\n",
    "def assert_sawer(reference_text, reference_speakers, recognized_text, recognized_speakers, ideal_report):\n",
    "    report = calculate_sawer(reference_text, reference_speakers, recognized_text, recognized_speakers)\n",
    "    for k, v in ideal_report.items():\n",
    "        assert v == report[k]\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e7120608",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import permutations\n",
    "\n",
    "def calculate_sawer(reference_text, reference_speakers, recognized_text, recognized_speakers):\n",
    "    assert isinstance(reference_text, list)\n",
    "    assert isinstance(recognized_text, list)\n",
    "    assert len(reference_text) == len(reference_speakers)\n",
    "    assert len(recognized_text) == len(recognized_speakers)\n",
    "    \n",
    "    # Расстояние Левенштейна для WER (подсчет ошибок вставки, удаления и замены)\n",
    "    def levenshtein_distance(ref, hyp):\n",
    "        dp = [[0] * (len(hyp) + 1) for _ in range(len(ref) + 1)]\n",
    "        for i in range(len(ref) + 1):\n",
    "            dp[i][0] = i\n",
    "        for j in range(len(hyp) + 1):\n",
    "            dp[0][j] = j\n",
    "        \n",
    "        for i in range(1, len(ref) + 1):\n",
    "            for j in range(1, len(hyp) + 1):\n",
    "                if ref[i-1] == hyp[j-1]:\n",
    "                    cost = 0\n",
    "                else:\n",
    "                    cost = 1\n",
    "                dp[i][j] = min(dp[i-1][j] + 1, dp[i][j-1] + 1, dp[i-1][j-1] + cost)\n",
    "        \n",
    "        return dp[len(ref)][len(hyp)], dp\n",
    "\n",
    "    # Подсчет ошибок спикеров для каждого маппинга\n",
    "    def calculate_speaker_error(reference_speakers, recognized_speakers, mapping):\n",
    "        speaker_errors = 0\n",
    "        for i, ref_speaker in enumerate(reference_speakers):\n",
    "            if ref_speaker != mapping[recognized_speakers[i]]:\n",
    "                speaker_errors += 1\n",
    "        return speaker_errors\n",
    "\n",
    "    # Все возможные маппинги спикеров\n",
    "    unique_speakers_ref = sorted(set(reference_speakers))\n",
    "    unique_speakers_rec = sorted(set(recognized_speakers))\n",
    "    \n",
    "    # Найдем все возможные соответствия дикторов\n",
    "    all_mappings = list(permutations(unique_speakers_rec, len(unique_speakers_ref)))\n",
    "\n",
    "    min_sawer = float('inf')\n",
    "    best_ali = []\n",
    "\n",
    "    # Расчет для каждого маппинга\n",
    "    for mapping in all_mappings:\n",
    "        mapping_dict = {rec_speaker: ref_speaker for rec_speaker, ref_speaker in zip(mapping, unique_speakers_ref)}\n",
    "        \n",
    "        # Расстояние Левенштейна\n",
    "        wer, dp_matrix = levenshtein_distance(reference_text, recognized_text)\n",
    "        \n",
    "        # Подсчет ошибок спикеров\n",
    "        speaker_error = calculate_speaker_error(reference_speakers, recognized_speakers, mapping_dict)\n",
    "        \n",
    "        # Подсчет общего количества правильных, удаленных и замененных слов\n",
    "        C = len(reference_text) - wer\n",
    "        D = dp_matrix[len(reference_text)][0]\n",
    "        S = dp_matrix[len(reference_text)][len(recognized_text)] - C\n",
    "        \n",
    "        # Подсчет SA-WER\n",
    "        sawer = (S + D + speaker_error) / (S + D + C + speaker_error)\n",
    "        \n",
    "        if sawer < min_sawer:\n",
    "            min_sawer = sawer\n",
    "            best_ali = [reference_text, recognized_text, mapping_dict]\n",
    "\n",
    "    return {\"sawer\": min_sawer * 100, \"ali\": best_ali}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "1c70f023-8c9f-4aeb-b4ee-fd41f2191c26",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[140], line 25\u001b[0m\n\u001b[0;32m     20\u001b[0m     assert_sawer([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mпривет\u001b[39m\u001b[38;5;124m'\u001b[39m], [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m], [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mпривет\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mстудент\u001b[39m\u001b[38;5;124m'\u001b[39m], [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m],  {\n\u001b[0;32m     21\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msawer\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;241m100\u001b[39m})\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest 3 passed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 25\u001b[0m \u001b[43mtest_sawer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[140], line 8\u001b[0m, in \u001b[0;36mtest_sawer\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest_sawer\u001b[39m():\n\u001b[1;32m----> 8\u001b[0m     \u001b[43massert_sawer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mпривет\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mстудент\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mA\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mB\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mпривет\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mстудент\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msawer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     assert_sawer([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mпривет\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mстудент\u001b[39m\u001b[38;5;124m'\u001b[39m], [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m], [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mпривет\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mстудент\u001b[39m\u001b[38;5;124m'\u001b[39m], [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m],  {\n\u001b[0;32m     11\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msawer\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;241m50\u001b[39m})\n\u001b[0;32m     12\u001b[0m     assert_sawer([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mпривет\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mстудент\u001b[39m\u001b[38;5;124m'\u001b[39m], [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m], [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mпривет\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mстудент\u001b[39m\u001b[38;5;124m'\u001b[39m], [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m],  {\n\u001b[0;32m     13\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msawer\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;241m0\u001b[39m})\n",
      "Cell \u001b[1;32mIn[140], line 4\u001b[0m, in \u001b[0;36massert_sawer\u001b[1;34m(reference_text, reference_speakers, recognized_text, recognized_speakers, ideal_report)\u001b[0m\n\u001b[0;32m      2\u001b[0m report \u001b[38;5;241m=\u001b[39m calculate_sawer(reference_text, reference_speakers, recognized_text, recognized_speakers)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m ideal_report\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m v \u001b[38;5;241m==\u001b[39m report[k]\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def assert_sawer(reference_text, reference_speakers, recognized_text, recognized_speakers, ideal_report):\n",
    "    report = calculate_sawer(reference_text, reference_speakers, recognized_text, recognized_speakers)\n",
    "    for k, v in ideal_report.items():\n",
    "        assert v == report[k]\n",
    "\n",
    "    \n",
    "def test_sawer():\n",
    "    assert_sawer(['привет', 'студент'], ['A', 'B'], ['привет', 'студент'], [1, 2],  {\n",
    "            \"sawer\" : 0})\n",
    "    assert_sawer(['привет', 'студент'], ['A', 'A'], ['привет', 'студент'], [1, 2],  {\n",
    "            \"sawer\" : 50})\n",
    "    assert_sawer(['привет', 'студент'], ['A', 'A'], ['привет', 'студент'], [0, 0],  {\n",
    "            \"sawer\" : 0})\n",
    "    assert_sawer(['привет', 'с'], ['A', 'B'], ['привет', 'студент'], [1, 2],  {\n",
    "            \"sawer\" : 50})\n",
    "    assert_sawer(['привет', 'с'], ['A', 'B'], ['привет'], [1],  {\n",
    "            \"sawer\" : 50})\n",
    "    assert_sawer(['привет'], ['A'], ['привет', 'студент'], [1, 0],  {\n",
    "            \"sawer\" : 100})\n",
    "    assert_sawer(['привет'], ['A'], ['привет', 'студент'], [0, 0],  {\n",
    "            \"sawer\" : 100})\n",
    "\n",
    "    print(f\"Test 3 passed\")\n",
    "    \n",
    "test_sawer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f758f45-926e-4d8b-a25f-c28578c6de0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
